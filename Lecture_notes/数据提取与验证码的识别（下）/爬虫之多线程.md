### 1. 引入

> 我们之前写的爬虫都是单个线程的？这怎么够？一旦一个地方卡到不动了，那不就永远等待下去了？为此我们可以使用多线程或者多进程来处理。
> 不建议你用这个，不过还是介绍下了，如果想看可以看看下面，不想浪费时间直接看

### 2. 如何使用

> 爬虫使用多线程来处理网络请求，使用线程来处理 URL 队列中的 url，然后将 url 返回的结果保存在另一个队列中，其它线程在读取这个队列中的数据，然后写到文件中去

### 3. 主要组成部分

#### 3.1 URL 队列和结果队列

将将要爬去的 url 放在一个队列中，这里使用标准库 Queue。访问 url 后的结果保存在结果队列中

初始化一个 URL 队列

```python
from queue import Queue
urls_queue = Queue()
out_queue = Queue()
```

#### 3.2 类包装

使用多个线程，不停的取 URL 队列中的 url，并进行处理：

```python
import threading

class ThreadCrawl(threading.Thread):
    def __init__(self, queue, out_queue):
        threading.Thread.__init__(self)
        self.queue = queue
        self.out_queue = out_queue

    def run(self):
        while True:
            item = self.queue.get()
```

如果队列为空，线程就会被阻塞，直到队列不为空。处理队列中的一条数据后，就需要通知队列已经处理完该条数据

#### 3.3 函数包装

```python
from threading import Thread
def func(args)
    pass
if __name__ == '__main__':
    info_html = Queue()
    t1 = Thread(target=func,args=(info_html,)
```

#### 3.4 线程池

```python
# 简单往队列中传输线程数
import threading
import time
import queue

class Threadingpool():
    def __init__(self,max_num = 10):
        self.queue = queue.Queue(max_num)
        for i in range(max_num):
            self.queue.put(threading.Thread)

    def getthreading(self):
        return self.queue.get()

    def addthreading(self):
        self.queue.put(threading.Thread)


def func(p,i):
    time.sleep(1)
    print(i)
    p.addthreading()


if __name__ == "__main__":
    p = Threadingpool()
    for i in range(20):
        thread = p.getthreading()
        t = thread(target = func, args = (p,i))
        t.start()
```

#### 4. Queue 模块中的常用方法:

Python 的 Queue 模块中提供了同步的、线程安全的队列类，包括 FIFO（先入先出)队列 Queue，LIFO（后入先出）队列 LifoQueue，和优先级队列 PriorityQueue。这些队列都实现了锁原语，能够在多线程中直接使用。可以使用队列来实现线程间的同步

- Queue.qsize() 返回队列的大小
- Queue.empty() 如果队列为空，返回 True,反之 False
- Queue.full() 如果队列满了，返回 True,反之 False
- Queue.full 与 maxsize 大小对应
- Queue.get([block[, timeout]])获取队列，timeout 等待时间
- Queue.get_nowait() 相当 Queue.get(False)
- Queue.put(item) 写入队列，timeout 等待时间
- Queue.put_nowait(item) 相当 Queue.put(item, False)
- Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号
- Queue.join() 实际上意味着等到队列为空，再执行别的操作
